Search Model Context Protocol (MCP)  on github.com 
最新小马智行（PONY）价值投资研究报告，公司估值和投资策略
Model Context Protocol(MCP) 开发环境工具链与技术生态调研报告
Report on: Model Context Protocol (MCP) Develop Tools and Tech Stacks, Using Web_Search tool, browser automation
搜索整理关于 社会学家“马克斯韦伯”的核心著作与思想，代表语录 ， 输出中文语言报告。
使用 `search_by_api` 工具 搜索整理关于 社会学家“马克斯韦伯”的核心著作与思想，代表语录 ， 输出中文语言报告。
搜索 arxiv 整理关于 Multi Agent System 的最新论文专题


# 搜索 arxiv 整理关于 Multi Agent System 的最新论文专题
---------------------------------------------------
Gathered information: Title: VAIN: Attentional Multi-agent Predictive Modeling
Date: 2017-06-19
PDF Url: http://arxiv.org/pdf/1706.06122v2

Multi-agent predictive modeling is an essential step for understanding
physical, social and team-play systems. Recently, Interaction Networks (INs)
were proposed for the task of modeling multi-agent physical systems, INs scale
[...]

-------

Title: The Athenian Academy: A Seven-Layer Architecture Model for Multi-Agent Systems
Date: 2025-04-17
PDF Url: http://arxiv.org/pdf/2504.12735v2

This paper proposes the "Academy of Athens" multi-agent seven-layer
framework, aimed at systematically addressing challenges in multi-agent systems
(MAS) within artificial intelligence (AI) art creation, such as collaboration
[...]

-------

Title: Agentic AI and Multiagentic: Are We Reinventing the Wheel?
Date: 2025-06-02
PDF Url: http://arxiv.org/pdf/2506.01463v1

The terms Agentic AI and Multiagentic AI have recently gained popularity in
discussions on generative artificial intelligence, often used to describe
autonomous software agents and systems composed of such agents. However, the
[...]

-------

Title: Are AI agents the new machine translation frontier? Challenges and opportunities of single- and multi-agent systems for multilingual digital communication
Date: 2025-04-17
PDF Url: http://arxiv.org/pdf/2504.12891v1

The rapid evolution of artificial intelligence (AI) has introduced AI agents
as a disruptive paradigm across various industries, yet their application in
machine translation (MT) remains underexplored. This paper describes and
[...]

-------

Title: Agent TCP/IP: An Agent-to-Agent Transaction System
Date: 2025-01-08
PDF Url: http://arxiv.org/pdf/2501.06243v1

Autonomous agents represent an inevitable evolution of the internet. Current
agent frameworks do not embed a standard protocol for agent-to-agent
interaction, leaving existing agents isolated from their peers. As intellectual
[...]

-------

Title: AutoGenesisAgent: Self-Generating Multi-Agent Systems for Complex Tasks
Date: 2024-04-25
PDF Url: http://arxiv.org/pdf/2404.17017v1

The proliferation of large language models (LLMs) and their integration into
multi-agent systems has paved the way for sophisticated automation in various
domains. This paper introduces AutoGenesisAgent, a multi-agent system that
[...]

-------

Title: LLM Multi-Agent Systems: Challenges and Open Problems
Date: 2024-02-05
PDF Url: http://arxiv.org/pdf/2402.03578v2

This paper explores multi-agent systems and identify challenges that remain
inadequately addressed. By leveraging the diverse capabilities and roles of
individual agents, multi-agent systems can tackle complex tasks through agent
[...]

-------

Title: PeerGuard: Defending Multi-Agent Systems Against Backdoor Attacks Through Mutual Reasoning
Date: 2025-05-16
PDF Url: http://arxiv.org/pdf/2505.11642v2

Multi-agent systems leverage advanced AI models as autonomous agents that
interact, cooperate, or compete to complete complex tasks across applications
such as robotics and traffic management. Despite their growing importance,
[...]

-------

Title: Impact of Relational Networks in Multi-Agent Learning: A Value-Based Factorization View
Date: 2023-10-19
PDF Url: http://arxiv.org/pdf/2310.12912v1

Effective coordination and cooperation among agents are crucial for
accomplishing individual or shared objectives in multi-agent systems. In many
real-world multi-agent systems, agents possess varying abilities and
[...]

-------

Title: Consensus of hierarchical multi-agent systems with a time-varying set of active agents
Date: 2022-12-01
PDF Url: http://arxiv.org/pdf/2212.00455v1

Time-varying hierarchical multi-agent systems are common in many
applications. A well-known solution to control these systems is to use state
feedback controllers that depend on the adjacency matrix to reach consensus.
[...]

-------

Title: Stability of Evolving Multi-Agent Systems
Date: 2011-11-30
PDF Url: http://arxiv.org/pdf/1111.7033v1

A Multi-Agent System is a distributed system where the agents or nodes
perform complex functions that cannot be written down in analytic form.
Multi-Agent Systems are highly connected, and the information they contain is
[...]

-------

Title: Multi-Agent Training for Pommerman: Curriculum Learning and Population-based Self-Play Approach
Date: 2024-06-30
PDF Url: http://arxiv.org/pdf/2407.00662v2

Pommerman is a multi-agent environment that has received considerable
attention from researchers in recent years. This environment is an ideal
benchmark for multi-agent training, providing a battleground for two teams with
[...]

-------

Title: Ontology-Based Feedback to Improve Runtime Control for Multi-Agent Manufacturing Systems
Date: 2023-09-18
PDF Url: http://arxiv.org/pdf/2309.10132v1

Improving the overall equipment effectiveness (OEE) of machines on the shop
floor is crucial to ensure the productivity and efficiency of manufacturing
systems. To achieve the goal of increased OEE, there is a need to develop
[...]

-------

Title: Consensus of Hybrid Multi-agent Systems
Date: 2015-12-10
PDF Url: http://arxiv.org/pdf/1512.03189v1

In this paper, we consider the consensus problem of hybrid multi-agent
system. First, the hybrid multi-agent system is proposed which is composed of
continuous-time and discrete-time dynamic agents. Then, three kinds of
[...]

-------

Title: Measuring collaborative emergent behavior in multi-agent reinforcement learning
Date: 2018-07-23
PDF Url: http://arxiv.org/pdf/1807.08663v1

Multi-agent reinforcement learning (RL) has important implications for the
future of human-agent teaming. We show that improved performance with
multi-agent RL is not a guarantee of the collaborative behavior thought to be
[...]

-------

Title: Multi-agent Policy Optimization with Approximatively Synchronous Advantage Estimation
Date: 2020-12-07
PDF Url: http://arxiv.org/pdf/2012.03488v3

Cooperative multi-agent tasks require agents to deduce their own
contributions with shared global rewards, known as the challenge of credit
assignment. General methods for policy based multi-agent reinforcement learning
[...]

-------

Title: Reciprocal Collision Avoidance for General Nonlinear Agents using Reinforcement Learning
Date: 2019-10-24
PDF Url: http://arxiv.org/pdf/1910.10887v2

Finding feasible and collision-free paths for multiple nonlinear agents is
challenging in the decentralized scenarios due to limited available information
of other agents and complex dynamics constraints. In this paper, we propose a
[...]

-------

Title: Stability analysis for large-scale multi-agent molecular communication systems
Date: 2023-11-12
PDF Url: http://arxiv.org/pdf/2311.06730v2

Molecular communication (MC) is recently featured as a novel communication
tool to connect individual biological nanorobots. It is expected that a large
number of nanorobots can form large multi-agent MC systems through MC to
[...]

-------

Title: Reaching a Consensus in Networks of High-Order Integral Agents under Switching Directed Topology
Date: 2013-04-15
PDF Url: http://arxiv.org/pdf/1304.3972v1

Consensus problem of high-order integral multi-agent systems under switching
directed topology is considered in this study. Depending on whether the agent's
full state is available or not, two distributed protocols are proposed to
[...]

-------

Title: Contract-based Design and Verification of Multi-Agent Systems with Quantitative Temporal Requirements
Date: 2024-12-17
PDF Url: http://arxiv.org/pdf/2412.13114v1

Quantitative requirements play an important role in the context of
multi-agent systems, where there is often a trade-off between the tasks of
individual agents and the constraints that the agents must jointly adhere to.
[...]
## Agentic AI and Multiagentic: Are We Reinventing the Wheel?

Vicent Botti

Valencian Research Institute for Artificial Intelligence (VRAIN) Universitat Politècnica de València (UPV) vbotti@vrain.upv.es

Valencian Graduated School and Research Network of Artificial Intelligence (ValgrAI)

## Abstract

The  terms  " Agentic  AI "  and  " Multiagentic  AI "  have  recently  gained  popularity  in  discussions  on generative  artificial  intelligence,  often  used  to  describe  autonomous  software  agents  and  systems composed  of  such  agents.  However,  the  use  of  these  terms  confuses  these  buzzwords  with  wellestablished concepts in AI literature: intelligent agents and multi-agent systems . This article offers a critical  analysis  of  this  conceptual  misuse.  We  review  the  theoretical  origins  of  "agentic"  in  the  social sciences (Bandura, 1986) and philosophical notions of intentionality (Dennett, 1971), and then summarise foundational works on intelligent agents and multi-agent systems by Wooldridge, Jennings and others. We examine  classic  agent  architectures -from  simple  reactive  agents  to  Belief-Desire-Intention  (BDI) models -and  highlight  key  properties  (autonomy,  reactivity,  proactivity,  social  capability)  that  define agency in AI. We then discuss recent developments in large language models (LLMs) and agent platforms based  on  LLMs,  including  the  emergence  of  LLM-powered  AI  agents  and  open-source  multi-agent orchestration frameworks. We argue that the term "AI Agentic" is often used as a buzzword for what are essentially AI agents, and "AI Multiagentic" for what are multi-agent systems. This confusion overlooks decades of research in the field of autonomous agents / multi-agent systems. The article advocates for scientific and technological rigour and the use of established terminology from the state of the art in AI, incorporating  the  wealth  of  existing  knowledge -including  standards  for  multi-agent  system  platforms, communication languages and coordination/cooperation algorithms, agreement technologies (automated negotiation, argumentation, virtual organisations, trust, reputation, etc.) -into the new and promising wave of LLM-based AI agents, so as not to end up reinventing the wheel .

## Introduction

Recent advances in generative AI , particularly large language models (LLMs), have led to a resurgence of interest in autonomous  software  agents : AI  systems  that  can  autonomously  perceive  their environment, reason, and act to meet their design goals to perform tasks on behalf of users. Visionaries such as Bill Gates predict that, in the near future, we will all have a personal AI assistant "far superiror to current technology," capable of responding to natural language requests and performing various tasks by understanding the user's goals [6]. Gates notes that this software, which he and others have imagined for decades, is finally becoming practical thanks to advances in AI, and that such " agents " could revolutionize our interaction with computers. In parallel, some industrial discourse, not always; there are many cases where the terminology is respected, has introduced new terms such as " Agentic AI " to describe AI systems endowed with autonomy and proactive decision-making. Technical blogs and articles differentiate between "AI agents" and "Agentic AI," presenting the latter as a general framework where multiple agents operate. Similarly,  the  term  " Multiagentic "  is  sometimes  used  for  systems  with  multiple  interacting  agents, analogous to classic multiagent systems .

This emergence of 'agentic' terminology in AI raises critical questions. Are these genuinely new concepts, or simply new labels for already established ideas in autonomous agents research? The field of intelligent agents and multi-agent systems (MAS) has a rich history dating back decades, with its  own theoretical

foundations,  architectures,  and  even  dedicated  conferences,  journals  and  scientific  associations  of researchers in the field. Before embracing the  hype  of 'agent ic AI,' it  is  important  to  examine  whether the term is being misapplied as a buzzword for capabilities long understood in AI -In other words, are we reinventing the wheel by equating agentic AI with intelligent agents and multiagentic systems with multiagent systems ?
## The Athenian Academy: A Seven-Layer Architecture Model for Multi-Agent Systems

Lidong Zhai ∗ a&amp; , Zhijie Qiu †∥ a , Lvyang Zhang ∗‡ , Jiaqi Li ∗‡ , Yi Wang , Wen Lu § ∗‡ Xizhong Guo ∗‡ , Ge Sun ¶

∗ Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China ‡ School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China † Tianjin Academy of Fine Arts, AI Art Institute, Tianjin, China ∥ Central Academy of Fine Arts, Institute of Science and Technology in Art, Beijing, China § Central Academy of Fine Arts, Beijing, China

¶ WaytoAGI, China

Abstract -This paper proposes the 'Academy of Athens' multi-agent seven-layer framework, aimed at systematically addressing challenges in multi-agent systems (MAS) within artificial intelligence (AI) art creation, such as collaboration efficiency, role allocation, environmental adaptation, and task parallelism. The framework divides MAS into seven layers: multi-agent collaboration, single-agent multi-role playing, single-agent multiscene traversal, single-agent multi-capability incarnation, different single agents using the same large model to achieve the same target agent, single-agent using different large models to achieve the same target agent, and multi-agent synthesis of the same target agent. Through experimental validation in art creation, the framework demonstrates its unique advantages in task collaboration, cross-scene adaptation, and model fusion. This paper further discusses current challenges such as collaboration mechanism optimization, model stability, and system security, proposing future exploration through technologies like metalearning and federated learning. The framework provides a structured methodology for multi-agent collaboration in AI art creation and promotes innovative applications in the art field.

keywords: Athenian Academy; Multi-Agent Systems; Artistic Creation;

## I. INTRODUCTION

In the grand scene of Raphael's painting 'The School of Athens', we see philosophers and thinkers engaged in passionate discussion, each striving to push the boundaries of human understanding and creativity. The painting is set on the walls of the sacred Academy of Athens, serving as a symbol of the intersection between wisdom and artistic expression, showcasing the collision, evolution, and generational transmission of ideas. Within this temple of knowledge, figures like Plato, Aristotle, and Socrates exchange profound insights, shaping the future of philosophical thought and artistic innovation. Just as these figures advanced the development of ideas through rigorous debate and creative exploration, modern artificial intelligence (AI) systems, particularly within the framework of multi-agent systems (MAS), are replicating this collaborative creativity through advanced computational methods.

This paper explores the intersection of multi-agent systems (MAS) and AI-driven art creation, proposing a new approach to explore how agents can aggregate their powers to create

a These authors contributed equally to this work.

&amp; Corresponding author: zhailidong@iie.ac.cn

Fig. 1: Raphael's The School of Athens

<!-- image -->

art that transcends individual limitations. MAS is a complex system composed of multiple autonomous agents interacting within a shared environment, which has long been a research topic in the field of artificial intelligence. MAS enables distributed decision-making, parallel processing, and strong environmental adaptability, all of which are crucial for solving complex dynamic tasks.

In recent years, AI-based art creation has gradually gained prominence, particularly due to the powerful capabilities of generative models and machine learning. These models can generate, manipulate, and evaluate art in unprecedented ways, pushing the boundaries of creativity. However, just like the ancient philosophers in 'The School of Athens', AI agents must also learn to interact, collaborate, and debate within a shared intellectual space to create cohesive and innovative artistic works. This paper proposes a framework inspired by 'The School of Athens', called the 'Academy of Athens Framework', for multi-agent art creation. The framework introduces a seven-layer MAS collaboration approach aimed at addressing the challenges and potentials in multi-agent art creation.

The 'Academy of Athens Framework' divides the collaboration process into seven layers, starting from the perception and cognition of individual agents, gradually advancing to agent collaboration, role allocation, and multi-agent coordination, and ultimately achieving the holistic creation of art. This method, as a structured abstract perspective, is employed to understand and solve complex system problems. This multilevel design not only facilitates a deeper analysis of the various components of the MAS but also provides a flexible structure for AI agents to engage in detailed and dynamic artistic creation.
## PeerGuard: Defending Multi-Agent Systems Against Backdoor Attacks Through Mutual Reasoning

1 st Falong Fan The Chinese University of Hong Kong, Shenzhen falongfan@link.cuhk.edu.cn

Abstract -Multi-agent systems leverage advanced AI models as autonomous agents that interact, cooperate, or compete to complete complex tasks across applications such as robotics and traffic management. Despite their growing importance, safety in multi-agent systems remains largely underexplored, with most research focusing on single AI models rather than interacting agents. This work investigates backdoor vulnerabilities in multiagent systems and proposes a defense mechanism based on agent interactions. By leveraging reasoning abilities, each agent evaluates responses from others to detect illogical reasoning processes, which indicate poisoned agents. Experiments on LLM-based multi-agent systems, including ChatGPT series and Llama 3, demonstrate the effectiveness of the proposed method, achieving high accuracy in identifying poisoned agents while minimizing false positives on clean agents. We believe this work provides insights into multi-agent system safety and contributes to the development of robust, trustworthy AI interactions. Our code is available in the link 1 at the footnote.

Index Terms -Multi-agent systems, Backdoor Defense, Large Language Models, Chain of Thoughts

## I. INTRODUCTION

Multi-agent systems (MAS) use large language models (LLMs) as autonomous agents that interact to accomplish complex tasks across various applications [1, 2]. While their use is expanding, safety in multi-agent settings remains underexplored, with most research focusing on individual models rather than agent interactions. These systems inherit vulnerabilities from LLMs: pre-training on large-scale Internet data introduces harmful content such as bias and racism [3]. Besides, advanced features like in-context learning make attacks easier to execute. For example, poisoning attacks can occur at inference time via malicious prompts, bypassing the need to alter training data [4, 5]. Such vulnerabilities may propagate and intensify through agent interactions [6], making trustworthiness a growing concern [7].

Among the threats to multi-agent systems, we focus on backdoor attacks - an established and potent class of attacks in the AI community. These attacks exploit a predefined trigger to induce malicious behavior in one or more agents while preserving normal performance on clean inputs. The attack can propagate through agent interactions and influence the collective decision-making process. The widespread use of third-party LLM services, including APIs and prompt

2 nd Xi Li

University of Alabama at Birmingham

XiLiUAB@uab.edu engineering tools, further increases the attack surface: unregulated providers may embed malicious instructions in prompts without altering the model itself [8, 9]. For example, in a multi-agent financial assistant system, a poisoned agent could be triggered to recommend risky investments, misleading the other agent in the debate and ultimately influencing the final consensus toward harmful outcomes.

However, existing backdoor defense research largely focuses on single LLMs and addresses a limited set of attack types, with minimal exploration in MAS. For instance, [10] proposes detecting out-of-distribution words in the input to defend against textual backdoor attacks, but this approach is ineffective against attacks that do not rely on irregular trigger tokens. Similarly, [11] filters suspicious content from training data, which is impractical for most modern LLMs accessed only via APIs without training data visibility. [12] introduces a coordinator agent in MAS to detect jailbreak attacks, but focuses solely on malicious prompts and overlooks the deeper threat of compromised models. Other works [13, 14] study prompt injection propagation across agents without altering the underlying model. In contrast, our work investigates modellevel backdoors that embed malicious behaviors directly into one or more agents, enabling selective triggering while preserving normal outputs in benign cases.

This work fills the gap by investigating backdoor vulnerabilities in multi-agent systems and proposing a defense mechanism that leverages agents' reasoning abilities and their interactions. Backdoor attacks cause LLM agents to learn a 'shortcut' from the trigger to the target output, bypassing logical reasoning. To mitigate this, we design demonstrations that encourage agents to explicitly generate reasoning steps, thereby reducing the likelihood of blindly following attackinduced shortcuts. Agents then inspect each other's reasoning process to identify inconsistencies between the rationale and the final answer. Any such inconsistency signals a lack of valid support and suggests potential backdoor manipulation. We integrate this defense strategy into existing multi-agent frameworks without disrupting their original interaction flow, thereby enhancing robustness in a plug-and-play manner. In summary, our main contributions are:

- · We propose PeerGuard: a collaborative defense strategy for multi-agent systems, in which agents autonomously verify each other's reasoning to detect backdoor-induced inconsistencies, enhancing overall system trustworthiness.

- · We empirically validate the proposed method on diverse benchmarks, demonstrating strong defense performance in GPT- and Llama3-based multi-agent systems.

## II. RELATED WORK
## LLMMulti-Agent Systems: Challenges and Open Problems

Shanshan Han 1 Qifan Zhang 1 Yuhang Yao 2 Weizhao Jin 3 Zhaozhuo Xu 4

## Abstract

This paper explores multi-agent systems and identify challenges that remain inadequately addressed. By leveraging the diverse capabilities and roles of individual agents, multi-agent systems can tackle complex tasks through agent collaboration. We discuss optimizing task allocation, fostering robust reasoning through iterative debates, managing complex and layered context information, and enhancing memory management to support the intricate interactions within multiagent systems. We also explore potential applications of multi-agent systems in blockchain systems to shed light on their future development and application in real-world distributed systems.

## 1. Introduction

Multi-agent systems enhance the capabilities of single LLM agents by leveraging collaborations among agents and their specialized abilities (Talebirad &amp; Nadiri, 2023; Zhang et al., 2023a; Park et al., 2023; Li et al., 2023; Jinxin et al., 2023). It utilizing collaboration and coordination among agents to execute tasks that are beyond the capability of any individual agent. In multi-agent systems, each agent is equipped with distinctive capabilities and roles, collaborating towards the fulfillment of some common objectives. Such collaboration, characterized by activities such as debate and reflection, has proven particularly effective for tasks requiring deep thought and innovation. Recent works include simulating interactive environments (Park et al., 2023; Jinxin et al., 2023), roleplaying (Li et al., 2023), reasoning (Du et al., 2023; Liang et al., 2023), demonstrating the huge potential of multi-agent systems in handling complex real-world scenarios.

While existing works have demonstrated the impressive capabilities of multi-agent systems, the potential for advanced multi-agent systems far exceeds the progress made to date.

1 University of California, Irvine, CA, USA 2 Carnegie Mellon University, Pittsburgh, PA, USA 3 University of Southern California, Los Angeles, CA, USA 4 Stevens Institute of Technology, Hoboken, NJ, USA. Correspondence to: Shanshan Han &lt; shanshan.han@uci.edu &gt; .

Alarge number of existing works focus on devising planning strategies within a single agent by breaking down the tasks into smaller, more manageable tasks (Chen et al., 2022; Ziqi &amp;Lu, 2023; Yao et al., 2023; Long, 2023; Besta et al., 2023; Wang et al., 2022b). Yet, multi-agent systems involve agents of various specializations and more complex interactions and layered context information, which poses challenges to the designing of the work flow as well as the whole system. Also, existing literature pays limited attention to memory storage, while memory plays a critical role in collaborations between agents. It enables agents to access to some common sense, aligning context with their tasks, and further, learn from past work flows and adapt their strategies accordingly.

To date, multiple significant challenges that differentiate multi-agent systems and single-agent systems remain inadequately addressed. We summarize them as follows.

- · Optimizing task allocation to leverage agents' unique skills and specializations.
- · Fostering robust reasoning through iterative debates or discussions among a subset of agents to enhance intermediate results.
- · Managing complex and layered context information, such as context for overall tasks, single agents, and some common knowledge between agents, while ensuring alignment to the general objective.
- · Managing various types of memory that serve for different objectives in coherent to the interactions in multiagent systems

This paper explores multi-agent systems, offering a survey of the existing works while shedding light on the challenges and open problems in it. We study major components in multi-agent systems, including planning and memory storage, and address unique challenges posed by multiagent systems, compared with single-agent systems. We also explore potential application of multi-agent systems in blockchain systems from two perspectives, including 1) utilizing multi-agent systems as tools, and 2) assigning an agent to each blockchain node to make it represent the user, such that the agent can can complete some tasks on behalf of the user in the blockchain network.

## 2. Overview

## 2.1. Structure of Multi-agent Systems

The structure of multi-agent systems can be categorized into various types, based on the each agent's functionality and their interactions.
## AutoGenesisAgent: Self-Generating Multi-Agent Systems for Complex Tasks

Jeremy R. Harper 1

1 Owl Health Works LLC, Indianapolis, IN

## Abstract

The proliferation of large language models (LLMs) and their integration into multi-agent systems has paved the way for sophisticated automation in various domains. This paper introduces AutoGenesisAgent, a multi-agent system that autonomously designs and deploys other multi-agent systems tailored for specific tasks. AutoGenesisAgent comprises several specialized agents including System Understanding, System Design, Agent Generator, and several others that collectively manage the lifecycle of creating functional multi-agent systems from initial concept to deployment. Each agent in AutoGenesisAgent has distinct responsibilities ranging from interpreting input prompts to optimizing system performance, culminating, in the deployment of a ready-to-use system. This proof-of-concept study discusses the design, implementation, and lessons learned from developing AutoGenesisAgent, highlighting its capability to generate and refine multi-agent systems autonomously, thereby reducing the need for extensive human oversight in the initial stages of system design.

Keywords: multi-agent systems, large language models, system design automation, agent architecture, autonomous systems, software deployment

## 1. Introduction

The integration of artificial intelligence into system design and automation has become a pivotal area of research and development, significantly impacting various industrial sectors by enhancing efficiency and decision-making processes. In particular, the advancement and application of large language models (LLMs) have heralded a new era in the development of intelligent systems capable of understanding and generating human-like text. AutoGenesisAgent, introduced in this paper, represents a novel contribution to this field by automating the design and deployment of multi-agent systems that are tailored to specific operational needs.

Unlike traditional multi-agent systems, AutoGenesisAgent adopts a model-agnostic approach, enabling it to operate effectively with various underlying technologies. This flexibility has been demonstrated through its application with several state-of-the-art models, including Llama 2, Llama 3, and Mistral 8x22b. These implementations highlight the system's capability to leverage different LLM architectures to fulfill the requirements of diverse tasks and environments, thereby underscoring its adaptability and broad applicability.

The motivation behind the development of AutoGenesisAgent stems from the recognized need for more dynamic and responsive systems in industries where traditional approaches to system design and project management can be inefficient and error-prone. Manual methods of creating multi-agent systems not only consume substantial time and resources but also lack the agility to adapt to rapidly changing conditions or integrate new insights without significant reconfiguration.

AutoGenesisAgent addresses these challenges by encapsulating the entire lifecycle of multi-agent system development, from initial conceptualization and system architecture design to deployment. Through this automated approach, the system facilitates a reduction in development time, minimizes human error, and ensures a high degree of customization and scalability.

This paper will detail the architecture and implementation of AutoGenesisAgent, how it is a prototype of the future process of system design. The insights gleaned from deploying AutoGenesisAgent where I will highlight not only the successes but also the lessons learned, which are vital for guiding future enhancements and research directions in automated system design. As we explore the capabilities and potential of an infrastructure such as AutoGenesisAgent, it becomes evident that this technology does not merely automate tasks but reshapes the landscape of system architecture and operational management.

## 2. System Architecture

The architecture of AutoGenesisAgent is structured to facilitate the seamless design, generation, and deployment of multi-agent systems tailored to specific tasks. This section outlines the architecture by detailing the roles and interactions of the constituent agents, each designed to handle specific aspects of the system creation process.

## 1. System Understanding Agent

The System Understanding Agent serves as the initial point of contact with the input specifications. It parses and interprets user-defined prompts that describe the desired functionality and scope of the target multi-agent system. This agent is responsible for extracting and structuring the necessary information to outline the types of agents needed, their expected interactions, and the overall functionality required. Its output is a comprehensive specification that serves as the blueprint for the subsequent design process.

## 2. System Design Agent

Following the specifications provided by the System Understanding Agent, the System Design Agent takes on the task of architecting the new system. It determines the optimal number and type of agents, delineates their roles, and designs the data flows and interaction protocols between them. The output from this agent is a detailed system blueprint that includes diagrams and data flow charts, ensuring that all components are aligned with the overall system goals.

## 3. Agent Generator
Report generation prompt: 
            Based on the following research information:
            --- START OF RESEARCH INFORMATION ---
            Title: VAIN: Attentional Multi-agent Predictive Modeling
Date: 2017-06-19
PDF Url: http://arxiv.org/pdf/1706.06122v2

Multi-agent predictive modeling is an essential step for understanding
physical, social and team-play systems. Recently, Interaction Networks (INs)
were proposed for the task of modeling multi-agent physical systems, INs scale
[...]

-------

Title: The Athenian Academy: A Seven-Layer Architecture Model for Multi-Agent Systems
Date: 2025-04-17
PDF Url: http://arxiv.org/pdf/2504.12735v2

This paper proposes the "Academy of Athens" multi-agent seven-layer
framework, aimed at systematically addressing challenges in multi-agent systems
(MAS) within artificial intelligence (AI) art creation, such as collaboration
[...]

-------

Title: Agentic AI and Multiagentic: Are We Reinventing the Wheel?
Date: 2025-06-02
PDF Url: http://arxiv.org/pdf/2506.01463v1

The terms Agentic AI and Multiagentic AI have recently gained popularity in
discussions on generative artificial intelligence, often used to describe
autonomous software agents and systems composed of such agents. However, the
[...]

-------

Title: Are AI agents the new machine translation frontier? Challenges and opportunities of single- and multi-agent systems for multilingual digital communication
Date: 2025-04-17
PDF Url: http://arxiv.org/pdf/2504.12891v1

The rapid evolution of artificial intelligence (AI) has introduced AI agents
as a disruptive paradigm across various industries, yet their application in
machine translation (MT) remains underexplored. This paper describes and
[...]

-------

Title: Agent TCP/IP: An Agent-to-Agent Transaction System
Date: 2025-01-08
PDF Url: http://arxiv.org/pdf/2501.06243v1

Autonomous agents represent an inevitable evolution of the internet. Current
agent frameworks do not embed a standard protocol for agent-to-agent
interaction, leaving existing agents isolated from their peers. As intellectual
[...]

-------

Title: AutoGenesisAgent: Self-Generating Multi-Agent Systems for Complex Tasks
Date: 2024-04-25
PDF Url: http://arxiv.org/pdf/2404.17017v1

The proliferation of large language models (LLMs) and their integration into
multi-agent systems has paved the way for sophisticated automation in various
domains. This paper introduces AutoGenesisAgent, a multi-agent system that
[...]

-------

Title: LLM Multi-Agent Systems: Challenges and Open Problems
Date: 2024-02-05
PDF Url: http://arxiv.org/pdf/2402.03578v2

This paper explores multi-agent systems and identify challenges that remain
inadequately addressed. By leveraging the diverse capabilities and roles of
individual agents, multi-agent systems can tackle complex tasks through agent
[...]

-------

Title: PeerGuard: Defending Multi-Agent Systems Against Backdoor Attacks Through Mutual Reasoning
Date: 2025-05-16
PDF Url: http://arxiv.org/pdf/2505.11642v2

Multi-agent systems leverage advanced AI models as autonomous agents that
interact, cooperate, or compete to complete complex tasks across applications
such as robotics and traffic management. Despite their growing importance,
[...]

-------

Title: Impact of Relational Networks in Multi-Agent Learning: A Value-Based Factorization View
Date: 2023-10-19
PDF Url: http://arxiv.org/pdf/2310.12912v1

Effective coordination and cooperation among agents are crucial for
accomplishing individual or shared objectives in multi-agent systems. In many
real-world multi-agent systems, agents possess varying abilities and
[...]

-------

Title: Consensus of hierarchical multi-agent systems with a time-varying set of active agents
Date: 2022-12-01
PDF Url: http://arxiv.org/pdf/2212.00455v1

Time-varying hierarchical multi-agent systems are common in many
applications. A well-known solution to control these systems is to use state
feedback controllers that depend on the adjacency matrix to reach consensus.
[...]

-------

Title: Stability of Evolving Multi-Agent Systems
Date: 2011-11-30
PDF Url: http://arxiv.org/pdf/1111.7033v1

A Multi-Agent System is a distributed system where the agents or nodes
perform complex functions that cannot be written down in analytic form.
Multi-Agent Systems are highly connected, and the information they contain is
[...]

-------

Title: Multi-Agent Training for Pommerman: Curriculum Learning and Population-based Self-Play Approach
Date: 2024-06-30
PDF Url: http://arxiv.org/pdf/2407.00662v2

Pommerman is a multi-agent environment that has received considerable
attention from researchers in recent years. This environment is an ideal
benchmark for multi-agent training, providing a battleground for two teams with
[...]

-------

Title: Ontology-Based Feedback to Improve Runtime Control for Multi-Agent Manufacturing Systems
Date: 2023-09-18
PDF Url: http://arxiv.org/pdf/2309.10132v1

Improving the overall equipment effectiveness (OEE) of machines on the shop
floor is crucial to ensure the productivity and efficiency of manufacturing
systems. To achieve the goal of increased OEE, there is a need to develop
[...]

-------

Title: Consensus of Hybrid Multi-agent Systems
Date: 2015-12-10
PDF Url: http://arxiv.org/pdf/1512.03189v1

In this paper, we consider the consensus problem of hybrid multi-agent
system. First, the hybrid multi-agent system is proposed which is composed of
continuous-time and discrete-time dynamic agents. Then, three kinds of
[...]

-------

Title: Measuring collaborative emergent behavior in multi-agent reinforcement learning
Date: 2018-07-23
PDF Url: http://arxiv.org/pdf/1807.08663v1

Multi-agent reinforcement learning (RL) has important implications for the
future of human-agent teaming. We show that improved performance with
multi-agent RL is not a guarantee of the collaborative behavior thought to be
[...]

-------

Title: Multi-agent Policy Optimization with Approximatively Synchronous Advantage Estimation
Date: 2020-12-07
PDF Url: http://arxiv.org/pdf/2012.03488v3

Cooperative multi-agent tasks require agents to deduce their own
contributions with shared global rewards, known as the challenge of credit
assignment. General methods for policy based multi-agent reinforcement learning
[...]

-------

Title: Reciprocal Collision Avoidance for General Nonlinear Agents using Reinforcement Learning
Date: 2019-10-24
PDF Url: http://arxiv.org/pdf/1910.10887v2

Finding feasible and collision-free paths for multiple nonlinear agents is
challenging in the decentralized scenarios due to limited available information
of other agents and complex dynamics constraints. In this paper, we propose a
[...]

-------

Title: Stability analysis for large-scale multi-agent molecular communication systems
Date: 2023-11-12
PDF Url: http://arxiv.org/pdf/2311.06730v2

Molecular communication (MC) is recently featured as a novel communication
tool to connect individual biological nanorobots. It is expected that a large
number of nanorobots can form large multi-agent MC systems through MC to
[...]

-------

Title: Reaching a Consensus in Networks of High-Order Integral Agents under Switching Directed Topology
Date: 2013-04-15
PDF Url: http://arxiv.org/pdf/1304.3972v1

Consensus problem of high-order integral multi-agent systems under switching
directed topology is considered in this study. Depending on whether the agent's
full state is available or not, two distributed protocols are proposed to
[...]

-------

Title: Contract-based Design and Verification of Multi-Agent Systems with Quantitative Temporal Requirements
Date: 2024-12-17
PDF Url: http://arxiv.org/pdf/2412.13114v1

Quantitative requirements play an important role in the context of
multi-agent systems, where there is often a trade-off between the tasks of
individual agents and the constraints that the agents must jointly adhere to.
[...]
## Agentic AI and Multiagentic: Are We Reinventing the Wheel?

Vicent Botti

Valencian Research Institute for Artificial Intelligence (VRAIN) Universitat Politècnica de València (UPV) vbotti@vrain.upv.es

Valencian Graduated School and Research Network of Artificial Intelligence (ValgrAI)

## Abstract

The  terms  " Agentic  AI "  and  " Multiagentic  AI "  have  recently  gained  popularity  in  discussions  on generative  artificial  intelligence,  often  used  to  describe  autonomous  software  agents  and  systems composed  of  such  agents.  However,  the  use  of  these  terms  confuses  these  buzzwords  with  wellestablished concepts in AI literature: intelligent agents and multi-agent systems . This article offers a critical  analysis  of  this  conceptual  misuse.  We  review  the  theoretical  origins  of  "agentic"  in  the  social sciences (Bandura, 1986) and philosophical notions of intentionality (Dennett, 1971), and then summarise foundational works on intelligent agents and multi-agent systems by Wooldridge, Jennings and others. We examine  classic  agent  architectures -from  simple  reactive  agents  to  Belief-Desire-Intention  (BDI) models -and  highlight  key  properties  (autonomy,  reactivity,  proactivity,  social  capability)  that  define agency in AI. We then discuss recent developments in large language models (LLMs) and agent platforms based  on  LLMs,  including  the  emergence  of  LLM-powered  AI  agents  and  open-source  multi-agent orchestration frameworks. We argue that the term "AI Agentic" is often used as a buzzword for what are essentially AI agents, and "AI Multiagentic" for what are multi-agent systems. This confusion overlooks decades of research in the field of autonomous agents / multi-agent systems. The article advocates for scientific and technological rigour and the use of established terminology from the state of the art in AI, incorporating  the  wealth  of  existing  knowledge -including  standards  for  multi-agent  system  platforms, communication languages and coordination/cooperation algorithms, agreement technologies (automated negotiation, argumentation, virtual organisations, trust, reputation, etc.) -into the new and promising wave of LLM-based AI agents, so as not to end up reinventing the wheel .

## Introduction

Recent advances in generative AI , particularly large language models (LLMs), have led to a resurgence of interest in autonomous  software  agents : AI  systems  that  can  autonomously  perceive  their environment, reason, and act to meet their design goals to perform tasks on behalf of users. Visionaries such as Bill Gates predict that, in the near future, we will all have a personal AI assistant "far superiror to current technology," capable of responding to natural language requests and performing various tasks by understanding the user's goals [6]. Gates notes that this software, which he and others have imagined for decades, is finally becoming practical thanks to advances in AI, and that such " agents " could revolutionize our interaction with computers. In parallel, some industrial discourse, not always; there are many cases where the terminology is respected, has introduced new terms such as " Agentic AI " to describe AI systems endowed with autonomy and proactive decision-making. Technical blogs and articles differentiate between "AI agents" and "Agentic AI," presenting the latter as a general framework where multiple agents operate. Similarly,  the  term  " Multiagentic "  is  sometimes  used  for  systems  with  multiple  interacting  agents, analogous to classic multiagent systems .

This emergence of 'agentic' terminology in AI raises critical questions. Are these genuinely new concepts, or simply new labels for already established ideas in autonomous agents research? The field of intelligent agents and multi-agent systems (MAS) has a rich history dating back decades, with its  own theoretical

foundations,  architectures,  and  even  dedicated  conferences,  journals  and  scientific  associations  of researchers in the field. Before embracing the  hype  of 'agent ic AI,' it  is  important  to  examine  whether the term is being misapplied as a buzzword for capabilities long understood in AI -In other words, are we reinventing the wheel by equating agentic AI with intelligent agents and multiagentic systems with multiagent systems ?
## The Athenian Academy: A Seven-Layer Architecture Model for Multi-Agent Systems

Lidong Zhai ∗ a&amp; , Zhijie Qiu †∥ a , Lvyang Zhang ∗‡ , Jiaqi Li ∗‡ , Yi Wang , Wen Lu § ∗‡ Xizhong Guo ∗‡ , Ge Sun ¶

∗ Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China ‡ School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China † Tianjin Academy of Fine Arts, AI Art Institute, Tianjin, China ∥ Central Academy of Fine Arts, Institute of Science and Technology in Art, Beijing, China § Central Academy of Fine Arts, Beijing, China

¶ WaytoAGI, China

Abstract -This paper proposes the 'Academy of Athens' multi-agent seven-layer framework, aimed at systematically addressing challenges in multi-agent systems (MAS) within artificial intelligence (AI) art creation, such as collaboration efficiency, role allocation, environmental adaptation, and task parallelism. The framework divides MAS into seven layers: multi-agent collaboration, single-agent multi-role playing, single-agent multiscene traversal, single-agent multi-capability incarnation, different single agents using the same large model to achieve the same target agent, single-agent using different large models to achieve the same target agent, and multi-agent synthesis of the same target agent. Through experimental validation in art creation, the framework demonstrates its unique advantages in task collaboration, cross-scene adaptation, and model fusion. This paper further discusses current challenges such as collaboration mechanism optimization, model stability, and system security, proposing future exploration through technologies like metalearning and federated learning. The framework provides a structured methodology for multi-agent collaboration in AI art creation and promotes innovative applications in the art field.

keywords: Athenian Academy; Multi-Agent Systems; Artistic Creation;

## I. INTRODUCTION

In the grand scene of Raphael's painting 'The School of Athens', we see philosophers and thinkers engaged in passionate discussion, each striving to push the boundaries of human understanding and creativity. The painting is set on the walls of the sacred Academy of Athens, serving as a symbol of the intersection between wisdom and artistic expression, showcasing the collision, evolution, and generational transmission of ideas. Within this temple of knowledge, figures like Plato, Aristotle, and Socrates exchange profound insights, shaping the future of philosophical thought and artistic innovation. Just as these figures advanced the development of ideas through rigorous debate and creative exploration, modern artificial intelligence (AI) systems, particularly within the framework of multi-agent systems (MAS), are replicating this collaborative creativity through advanced computational methods.

This paper explores the intersection of multi-agent systems (MAS) and AI-driven art creation, proposing a new approach to explore how agents can aggregate their powers to create

a These authors contributed equally to this work.

&amp; Corresponding author: zhailidong@iie.ac.cn

Fig. 1: Raphael's The School of Athens

<!-- image -->

art that transcends individual limitations. MAS is a complex system composed of multiple autonomous agents interacting within a shared environment, which has long been a research topic in the field of artificial intelligence. MAS enables distributed decision-making, parallel processing, and strong environmental adaptability, all of which are crucial for solving complex dynamic tasks.

In recent years, AI-based art creation has gradually gained prominence, particularly due to the powerful capabilities of generative models and machine learning. These models can generate, manipulate, and evaluate art in unprecedented ways, pushing the boundaries of creativity. However, just like the ancient philosophers in 'The School of Athens', AI agents must also learn to interact, collaborate, and debate within a shared intellectual space to create cohesive and innovative artistic works. This paper proposes a framework inspired by 'The School of Athens', called the 'Academy of Athens Framework', for multi-agent art creation. The framework introduces a seven-layer MAS collaboration approach aimed at addressing the challenges and potentials in multi-agent art creation.

The 'Academy of Athens Framework' divides the collaboration process into seven layers, starting from the perception and cognition of individual agents, gradually advancing to agent collaboration, role allocation, and multi-agent coordination, and ultimately achieving the holistic creation of art. This method, as a structured abstract perspective, is employed to understand and solve complex system problems. This multilevel design not only facilitates a deeper analysis of the various components of the MAS but also provides a flexible structure for AI agents to engage in detailed and dynamic artistic creation.
## PeerGuard: Defending Multi-Agent Systems Against Backdoor Attacks Through Mutual Reasoning

1 st Falong Fan The Chinese University of Hong Kong, Shenzhen falongfan@link.cuhk.edu.cn

Abstract -Multi-agent systems leverage advanced AI models as autonomous agents that interact, cooperate, or compete to complete complex tasks across applications such as robotics and traffic management. Despite their growing importance, safety in multi-agent systems remains largely underexplored, with most research focusing on single AI models rather than interacting agents. This work investigates backdoor vulnerabilities in multiagent systems and proposes a defense mechanism based on agent interactions. By leveraging reasoning abilities, each agent evaluates responses from others to detect illogical reasoning processes, which indicate poisoned agents. Experiments on LLM-based multi-agent systems, including ChatGPT series and Llama 3, demonstrate the effectiveness of the proposed method, achieving high accuracy in identifying poisoned agents while minimizing false positives on clean agents. We believe this work provides insights into multi-agent system safety and contributes to the development of robust, trustworthy AI interactions. Our code is available in the link 1 at the footnote.

Index Terms -Multi-agent systems, Backdoor Defense, Large Language Models, Chain of Thoughts

## I. INTRODUCTION

Multi-agent systems (MAS) use large language models (LLMs) as autonomous agents that interact to accomplish complex tasks across various applications [1, 2]. While their use is expanding, safety in multi-agent settings remains underexplored, with most research focusing on individual models rather than agent interactions. These systems inherit vulnerabilities from LLMs: pre-training on large-scale Internet data introduces harmful content such as bias and racism [3]. Besides, advanced features like in-context learning make attacks easier to execute. For example, poisoning attacks can occur at inference time via malicious prompts, bypassing the need to alter training data [4, 5]. Such vulnerabilities may propagate and intensify through agent interactions [6], making trustworthiness a growing concern [7].

Among the threats to multi-agent systems, we focus on backdoor attacks - an established and potent class of attacks in the AI community. These attacks exploit a predefined trigger to induce malicious behavior in one or more agents while preserving normal performance on clean inputs. The attack can propagate through agent interactions and influence the collective decision-making process. The widespread use of third-party LLM services, including APIs and prompt

2 nd Xi Li

University of Alabama at Birmingham

XiLiUAB@uab.edu engineering tools, further increases the attack surface: unregulated providers may embed malicious instructions in prompts without altering the model itself [8, 9]. For example, in a multi-agent financial assistant system, a poisoned agent could be triggered to recommend risky investments, misleading the other agent in the debate and ultimately influencing the final consensus toward harmful outcomes.

However, existing backdoor defense research largely focuses on single LLMs and addresses a limited set of attack types, with minimal exploration in MAS. For instance, [10] proposes detecting out-of-distribution words in the input to defend against textual backdoor attacks, but this approach is ineffective against attacks that do not rely on irregular trigger tokens. Similarly, [11] filters suspicious content from training data, which is impractical for most modern LLMs accessed only via APIs without training data visibility. [12] introduces a coordinator agent in MAS to detect jailbreak attacks, but focuses solely on malicious prompts and overlooks the deeper threat of compromised models. Other works [13, 14] study prompt injection propagation across agents without altering the underlying model. In contrast, our work investigates modellevel backdoors that embed malicious behaviors directly into one or more agents, enabling selective triggering while preserving normal outputs in benign cases.

This work fills the gap by investigating backdoor vulnerabilities in multi-agent systems and proposing a defense mechanism that leverages agents' reasoning abilities and their interactions. Backdoor attacks cause LLM agents to learn a 'shortcut' from the trigger to the target output, bypassing logical reasoning. To mitigate this, we design demonstrations that encourage agents to explicitly generate reasoning steps, thereby reducing the likelihood of blindly following attackinduced shortcuts. Agents then inspect each other's reasoning process to identify inconsistencies between the rationale and the final answer. Any such inconsistency signals a lack of valid support and suggests potential backdoor manipulation. We integrate this defense strategy into existing multi-agent frameworks without disrupting their original interaction flow, thereby enhancing robustness in a plug-and-play manner. In summary, our main contributions are:

- · We propose PeerGuard: a collaborative defense strategy for multi-agent systems, in which agents autonomously verify each other's reasoning to detect backdoor-induced inconsistencies, enhancing overall system trustworthiness.

- · We empirically validate the proposed method on diverse benchmarks, demonstrating strong defense performance in GPT- and Llama3-based multi-agent systems.

## II. RELATED WORK
## LLMMulti-Agent Systems: Challenges and Open Problems

Shanshan Han 1 Qifan Zhang 1 Yuhang Yao 2 Weizhao Jin 3 Zhaozhuo Xu 4

## Abstract

This paper explores multi-agent systems and identify challenges that remain inadequately addressed. By leveraging the diverse capabilities and roles of individual agents, multi-agent systems can tackle complex tasks through agent collaboration. We discuss optimizing task allocation, fostering robust reasoning through iterative debates, managing complex and layered context information, and enhancing memory management to support the intricate interactions within multiagent systems. We also explore potential applications of multi-agent systems in blockchain systems to shed light on their future development and application in real-world distributed systems.

## 1. Introduction

Multi-agent systems enhance the capabilities of single LLM agents by leveraging collaborations among agents and their specialized abilities (Talebirad &amp; Nadiri, 2023; Zhang et al., 2023a; Park et al., 2023; Li et al., 2023; Jinxin et al., 2023). It utilizing collaboration and coordination among agents to execute tasks that are beyond the capability of any individual agent. In multi-agent systems, each agent is equipped with distinctive capabilities and roles, collaborating towards the fulfillment of some common objectives. Such collaboration, characterized by activities such as debate and reflection, has proven particularly effective for tasks requiring deep thought and innovation. Recent works include simulating interactive environments (Park et al., 2023; Jinxin et al., 2023), roleplaying (Li et al., 2023), reasoning (Du et al., 2023; Liang et al., 2023), demonstrating the huge potential of multi-agent systems in handling complex real-world scenarios.

While existing works have demonstrated the impressive capabilities of multi-agent systems, the potential for advanced multi-agent systems far exceeds the progress made to date.

1 University of California, Irvine, CA, USA 2 Carnegie Mellon University, Pittsburgh, PA, USA 3 University of Southern California, Los Angeles, CA, USA 4 Stevens Institute of Technology, Hoboken, NJ, USA. Correspondence to: Shanshan Han &lt; shanshan.han@uci.edu &gt; .

Alarge number of existing works focus on devising planning strategies within a single agent by breaking down the tasks into smaller, more manageable tasks (Chen et al., 2022; Ziqi &amp;Lu, 2023; Yao et al., 2023; Long, 2023; Besta et al., 2023; Wang et al., 2022b). Yet, multi-agent systems involve agents of various specializations and more complex interactions and layered context information, which poses challenges to the designing of the work flow as well as the whole system. Also, existing literature pays limited attention to memory storage, while memory plays a critical role in collaborations between agents. It enables agents to access to some common sense, aligning context with their tasks, and further, learn from past work flows and adapt their strategies accordingly.

To date, multiple significant challenges that differentiate multi-agent systems and single-agent systems remain inadequately addressed. We summarize them as follows.

- · Optimizing task allocation to leverage agents' unique skills and specializations.
- · Fostering robust reasoning through iterative debates or discussions among a subset of agents to enhance intermediate results.
- · Managing complex and layered context information, such as context for overall tasks, single agents, and some common knowledge between agents, while ensuring alignment to the general objective.
- · Managing various types of memory that serve for different objectives in coherent to the interactions in multiagent systems

This paper explores multi-agent systems, offering a survey of the existing works while shedding light on the challenges and open problems in it. We study major components in multi-agent systems, including planning and memory storage, and address unique challenges posed by multiagent systems, compared with single-agent systems. We also explore potential application of multi-agent systems in blockchain systems from two perspectives, including 1) utilizing multi-agent systems as tools, and 2) assigning an agent to each blockchain node to make it represent the user, such that the agent can can complete some tasks on behalf of the user in the blockchain network.

## 2. Overview

## 2.1. Structure of Multi-agent Systems

The structure of multi-agent systems can be categorized into various types, based on the each agent's functionality and their interactions.
## AutoGenesisAgent: Self-Generating Multi-Agent Systems for Complex Tasks

Jeremy R. Harper 1

1 Owl Health Works LLC, Indianapolis, IN

## Abstract

The proliferation of large language models (LLMs) and their integration into multi-agent systems has paved the way for sophisticated automation in various domains. This paper introduces AutoGenesisAgent, a multi-agent system that autonomously designs and deploys other multi-agent systems tailored for specific tasks. AutoGenesisAgent comprises several specialized agents including System Understanding, System Design, Agent Generator, and several others that collectively manage the lifecycle of creating functional multi-agent systems from initial concept to deployment. Each agent in AutoGenesisAgent has distinct responsibilities ranging from interpreting input prompts to optimizing system performance, culminating, in the deployment of a ready-to-use system. This proof-of-concept study discusses the design, implementation, and lessons learned from developing AutoGenesisAgent, highlighting its capability to generate and refine multi-agent systems autonomously, thereby reducing the need for extensive human oversight in the initial stages of system design.

Keywords: multi-agent systems, large language models, system design automation, agent architecture, autonomous systems, software deployment

## 1. Introduction

The integration of artificial intelligence into system design and automation has become a pivotal area of research and development, significantly impacting various industrial sectors by enhancing efficiency and decision-making processes. In particular, the advancement and application of large language models (LLMs) have heralded a new era in the development of intelligent systems capable of understanding and generating human-like text. AutoGenesisAgent, introduced in this paper, represents a novel contribution to this field by automating the design and deployment of multi-agent systems that are tailored to specific operational needs.

Unlike traditional multi-agent systems, AutoGenesisAgent adopts a model-agnostic approach, enabling it to operate effectively with various underlying technologies. This flexibility has been demonstrated through its application with several state-of-the-art models, including Llama 2, Llama 3, and Mistral 8x22b. These implementations highlight the system's capability to leverage different LLM architectures to fulfill the requirements of diverse tasks and environments, thereby underscoring its adaptability and broad applicability.

The motivation behind the development of AutoGenesisAgent stems from the recognized need for more dynamic and responsive systems in industries where traditional approaches to system design and project management can be inefficient and error-prone. Manual methods of creating multi-agent systems not only consume substantial time and resources but also lack the agility to adapt to rapidly changing conditions or integrate new insights without significant reconfiguration.

AutoGenesisAgent addresses these challenges by encapsulating the entire lifecycle of multi-agent system development, from initial conceptualization and system architecture design to deployment. Through this automated approach, the system facilitates a reduction in development time, minimizes human error, and ensures a high degree of customization and scalability.

This paper will detail the architecture and implementation of AutoGenesisAgent, how it is a prototype of the future process of system design. The insights gleaned from deploying AutoGenesisAgent where I will highlight not only the successes but also the lessons learned, which are vital for guiding future enhancements and research directions in automated system design. As we explore the capabilities and potential of an infrastructure such as AutoGenesisAgent, it becomes evident that this technology does not merely automate tasks but reshapes the landscape of system architecture and operational management.

## 2. System Architecture

The architecture of AutoGenesisAgent is structured to facilitate the seamless design, generation, and deployment of multi-agent systems tailored to specific tasks. This section outlines the architecture by detailing the roles and interactions of the constituent agents, each designed to handle specific aspects of the system creation process.

## 1. System Understanding Agent

The System Understanding Agent serves as the initial point of contact with the input specifications. It parses and interprets user-defined prompts that describe the desired functionality and scope of the target multi-agent system. This agent is responsible for extracting and structuring the necessary information to outline the types of agents needed, their expected interactions, and the overall functionality required. Its output is a comprehensive specification that serves as the blueprint for the subsequent design process.

## 2. System Design Agent

Following the specifications provided by the System Understanding Agent, the System Design Agent takes on the task of architecting the new system. It determines the optimal number and type of agents, delineates their roles, and designs the data flows and interaction protocols between them. The output from this agent is a detailed system blueprint that includes diagrams and data flow charts, ensuring that all components are aligned with the overall system goals.

## 3. Agent Generator
            --- END OF RESEARCH INFORMATION ---

            And the original research request:
            Topic: 搜索 arxiv 整理关于 Multi Agent System 的最新论文专题
            Depth: medium
            Format: markdown

            Please generate a comprehensive research report. The report should be in markdown format and include:
            - A clear title and summary
            - Well-structured sections covering all aspects of the topic
            - Proper citations and references (ensure these are based on the research information)
            - Actionable insights and recommendations

            The output should be ONLY the report content in the specified format.




----------------------------------------------------------------------------------

